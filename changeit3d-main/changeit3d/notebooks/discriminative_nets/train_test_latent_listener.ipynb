{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A notebook version of the scripts/train_test_latent_listener.py\n",
    "\n",
    "- here you can train your neural listener using the latent codes of a pretrained shape encoding system (e.g., PC-AE, SGF, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from ast import literal_eval\n",
    "\n",
    "from changeit3d.in_out.basics import (unpickle_data,\n",
    "                                      create_logger,\n",
    "                                      pickle_data,\n",
    "                                      torch_save_model,\n",
    "                                      save_state_dicts,\n",
    "                                      load_state_dicts)\n",
    "\n",
    "from changeit3d.in_out.arguments import parse_train_test_latent_listener_arguments\n",
    "from changeit3d.in_out.language_contrastive_dataset import LanguageContrastiveDataset\n",
    "from changeit3d.language.vocabulary import Vocabulary\n",
    "from changeit3d.models.listening_oriented import ablation_model_one, ablation_model_two\n",
    "from changeit3d.models.listening_oriented import single_epoch_train, evaluate_listener\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      "\n",
      "Input arguments:\n",
      "\n",
      "\u001b[0m\n",
      "{'add_shape_glot': False,\n",
      " 'batch_size': 2048,\n",
      " 'do_training': False,\n",
      " 'experiment_tag': None,\n",
      " 'gpu_id': 0,\n",
      " 'init_lr': 0.0005,\n",
      " 'latent_codes_file': '/home/panos/Git_Repos/changeit3d/changeit3d/data/pretrained/shape_latents/pcae_latent_codes.pkl',\n",
      " 'listening_model': 'ablation_model_one',\n",
      " 'log_dir': '/home/panos/Git_Repos/changeit3d/changeit3d/data/scratch/08-14-2023-00-33-06',\n",
      " 'lr_patience': 8,\n",
      " 'max_train_epochs': 100,\n",
      " 'num_workers': 10,\n",
      " 'pretrained_model_file': '/home/panos/Git_Repos/changeit3d/changeit3d/data/pretrained/listeners/all_shapetalk_classes/rs_2022/single_utter/transformer_based/latent_pcae_based/best_model.pt',\n",
      " 'random_seed': 2022,\n",
      " 'restrict_shape_class': [],\n",
      " 'save_analysis_results': False,\n",
      " 'shape_talk_file': '/home/panos/Git_Repos/changeit3d/changeit3d/data/shapetalk/language/shapetalk_preprocessed_public_version_0.csv',\n",
      " 'train_patience': 15,\n",
      " 'use_timestamp': True,\n",
      " 'vocab_file': '/home/panos/Git_Repos/changeit3d/changeit3d/data/shapetalk/language/vocabulary.pkl',\n",
      " 'weight_decay': 0.001}\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "### Argument handling -- specify your files/directories  (see documentation of  \n",
    "###                                                       arguments/parse_train_test_latent_listener_arguments() for more details on the \n",
    "###                                                       arguments)\n",
    "\n",
    "shape_talk_file = '/home/panos/Git_Repos/changeit3d/changeit3d/data/shapetalk/language/shapetalk_preprocessed_public_version_0.csv'\n",
    "vocab_file = '/home/panos/Git_Repos/changeit3d/changeit3d/data/shapetalk/language/vocabulary.pkl'   \n",
    "log_dir = '/home/panos/Git_Repos/changeit3d/changeit3d/data/scratch'\n",
    "random_seed = 2022\n",
    "\n",
    "\n",
    "### SPECIFY latent codes for shapes  (you can download our pretrained ones!)\n",
    "shape_latent_encoder = 'pcae'  # we provide more: e.g., \"pcae\", \"imnet\", \"resnet101\"\n",
    "top_pretrained_dir = '/home/panos/Git_Repos/changeit3d/changeit3d/data/pretrained'\n",
    "latent_codes_file = f'{top_pretrained_dir}/shape_latents/{shape_latent_encoder}_latent_codes.pkl'\n",
    "\n",
    "weight_decay = None # will use the default\n",
    "if shape_latent_encoder == \"resnet101\":        \n",
    "    weight_decay = 0.005 # increase weight decay to compensate for larger latent space\n",
    "\n",
    "    \n",
    "notebook_args = [\n",
    "    '-shape_talk_file', shape_talk_file,\n",
    "    '-vocab_file', vocab_file,\n",
    "    '-latent_codes_file', latent_codes_file,\n",
    "    '--log_dir', log_dir,    \n",
    "    '--gpu_id', '0'\n",
    "]\n",
    "\n",
    "if weight_decay is not None:\n",
    "    notebook_args.extend(['--weight_decay', str(weight_decay)])    \n",
    "\n",
    "### comment out if you want to load a specific (pretrained) LISTENER and optionally also avoid training it altogether\n",
    "### pretrained listeners can be downloaded here:\n",
    "###     https://shapetalk-public.s3.amazonaws.com/pretrained-nets/listeners.zip\n",
    "###     (see also scripts/bash_scripts/download_pretrained_nets.sh)\n",
    "\n",
    "notebook_args.extend(['--do_training', False,                       \n",
    "                      '--pretrained_model_file', '/home/panos/Git_Repos/changeit3d/changeit3d/data/pretrained/listeners/all_shapetalk_classes/rs_2022/single_utter/transformer_based/latent_pcae_based/best_model.pt',\n",
    "                      '--save_analysis_results', False])    \n",
    "\n",
    "\n",
    "args = parse_train_test_latent_listener_arguments(notebook_args)\n",
    "logger = create_logger(args.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent codes with dimension 256 are loaded.\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Prepare the input data\n",
    "##\n",
    "shape_to_latent_code = next(unpickle_data(args.latent_codes_file))\n",
    "shape_latent_dim = len(list(shape_to_latent_code.values())[0])\n",
    "logger.info('Latent codes with dimension {} are loaded.'.format(shape_latent_dim))\n",
    "\n",
    "df = pd.read_csv(args.shape_talk_file)\n",
    "df.tokens_encoded = df.tokens_encoded.apply(literal_eval)\n",
    "vocab = Vocabulary.load(args.vocab_file)\n",
    "\n",
    "if args.add_shape_glot:\n",
    "    raise NotImplementedError('left out of public code')\n",
    "\n",
    "# constraint training in language of particular classes\n",
    "if len(args.restrict_shape_class) > 0:\n",
    "    mask = df.target_object_class.isin(set(args.restrict_shape_class))\n",
    "    df = df[mask].copy()\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    logger.info('Restricting to class(es) {}. Total utterances: {}'.format(args.restrict_shape_class, len(df)))\n",
    "\n",
    "assert df.target_uid.apply(lambda x: x in shape_to_latent_code).all(), 'all loaded stimuli must have a latent code'\n",
    "assert df.source_uid.apply(lambda x: x in shape_to_latent_code).all(), 'all loaded stimuli must have a latent code'\n",
    "\n",
    "##\n",
    "# Prepare the data loaders\n",
    "##\n",
    "\n",
    "# make df compatible with LanguageContrastive Dataset\n",
    "df = df.assign(target=df.target_uid)\n",
    "df = df.assign(distractor_1=df.source_uid)\n",
    "\n",
    "def to_stimulus_func(x):\n",
    "    return shape_to_latent_code[x]\n",
    "\n",
    "dataloaders = dict()\n",
    "for split in ['train', 'val', 'test']:\n",
    "    ndf = df[df.listening_split == split].copy()\n",
    "    ndf.reset_index(inplace=True, drop=True)\n",
    "    seed = None if split == 'train' else args.random_seed\n",
    "    batch_size = args.batch_size if split == 'train' else 2 * args.batch_size\n",
    "    shuffle_items = split == 'train'\n",
    "\n",
    "    dataset = LanguageContrastiveDataset(ndf,\n",
    "                                         to_stimulus_func,\n",
    "                                         n_distractors=1,\n",
    "                                         shuffle_items=shuffle_items)\n",
    "\n",
    "    dataloaders[split] = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                                     batch_size=args.batch_size,\n",
    "                                                     shuffle=shuffle_items,\n",
    "                                                     num_workers=args.num_workers,\n",
    "                                                     worker_init_fn=lambda x: np.random.seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening Architecture:\n",
      "ContextFreeListener(\n",
      "  (language_encoder): TransformerModel(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.3, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.3, inplace=False)\n",
      "          (dropout2): Dropout(p=0.3, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (encoder): Embedding(5883, 128)\n",
      "  )\n",
      "  (stimulus_encoder): MLP(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout(p=0.3, inplace=False)\n",
      "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier_head): MLP(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=200, bias=True)\n",
      "      (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Linear(in_features=200, out_features=100, bias=True)\n",
      "      (4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): Linear(in_features=100, out_features=50, bias=True)\n",
      "      (7): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): Linear(in_features=50, out_features=1, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Loading pretrained listener @epoch 32\n",
      "Test accuracy at that loaded epoch is : 0.7142348287433681\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Build Listening Model\n",
    "##\n",
    "\n",
    "if args.listening_model == 'ablation_model_one':\n",
    "    model = ablation_model_one(vocab, shape_latent_dim)\n",
    "elif args.listening_model == 'ablation_model_two':\n",
    "    model = ablation_model_two(vocab, shape_latent_dim)\n",
    "else:\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print('Listening Architecture:')\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda:\" + str(args.gpu_id))\n",
    "model = model.to(device)\n",
    "\n",
    "if args.pretrained_model_file is not None:\n",
    "    best_epoch = load_state_dicts(args.pretrained_model_file, model=model, map_location=\"cpu\")\n",
    "    logger.info(f'Loading pretrained listener @epoch {best_epoch}')\n",
    "    test_acc = evaluate_listener(model, dataloaders['test'], device=device, return_logits=True)['accuracy']\n",
    "    logger.info(f'Test accuracy at that loaded epoch is : {test_acc}')\n",
    "    \n",
    "##\n",
    "# Optimization\n",
    "##\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.init_lr, weight_decay=args.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\",\n",
    "                                                          factor=0.5, patience=args.lr_patience,\n",
    "                                                          verbose=True, min_lr=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Training.\n",
    "##\n",
    "if args.do_training:\n",
    "\n",
    "    epochs_val_not_improved = best_test_accuracy = best_val_accuracy = 0\n",
    "    start_epoch = 1\n",
    "    checkpoint_file = osp.join(args.log_dir, 'best_model.pt')\n",
    "    logger.info('Start training of the listener.')\n",
    "\n",
    "    for epoch in range(start_epoch + 1, start_epoch + args.max_train_epochs + 1):\n",
    "        np.random.seed()\n",
    "        train_acc = single_epoch_train(model,\n",
    "                                       dataloaders['train'],\n",
    "                                       criterion, optimizer, device=device)['accuracy']\n",
    "\n",
    "        logger.info(f\"@epoch-{epoch} train {train_acc:.3f}\")\n",
    "\n",
    "        for split in ['val', 'test']:\n",
    "            epoch_accuracy = evaluate_listener(model, dataloaders[split], device=device)['accuracy']\n",
    "\n",
    "            if split == 'val':\n",
    "                lr_scheduler.step(epoch_accuracy)\n",
    "\n",
    "                if epoch_accuracy > best_val_accuracy:\n",
    "                    epochs_val_not_improved = 0\n",
    "                    best_val_accuracy = epoch_accuracy\n",
    "                    save_state_dicts(checkpoint_file, epoch=epoch, model=model,\n",
    "                                     optimizer=optimizer, lr_scheduler=lr_scheduler)\n",
    "                else:\n",
    "                    epochs_val_not_improved += 1\n",
    "\n",
    "            logger.info(\"{} {:.3f}\".format(split, epoch_accuracy))\n",
    "\n",
    "            if split == 'test' and epochs_val_not_improved == 0:\n",
    "                best_test_accuracy = epoch_accuracy\n",
    "\n",
    "        if epochs_val_not_improved == 0:\n",
    "            logger.info(\"* validation accuracy improved *\")\n",
    "\n",
    "        logger.info(\"\\nbest test accuracy {:.3f}\".format(best_test_accuracy))\n",
    "\n",
    "        if epochs_val_not_improved == args.train_patience:\n",
    "            logger.warning(\n",
    "                f'Validation loss did not improve for {epochs_val_not_improved} consecutive epochs. Training is stopped.')\n",
    "            break\n",
    "\n",
    "    # Load newly trained model with best per-validation loss.\n",
    "    logger.info('Training is done!')\n",
    "    best_epoch = load_state_dicts(checkpoint_file, model=model)\n",
    "    logger.info(f'per-validation optimal epoch {best_epoch}')\n",
    "    test_acc = evaluate_listener(model, dataloaders['test'], device=device, return_logits=True)['accuracy']\n",
    "    logger.info(f'(verifying) test accuracy at that epoch is : {test_acc}')\n",
    "\n",
    "    # save one more time the model, this time as a module directly working for inference\n",
    "    checkpoint_pkl_file = checkpoint_file = osp.join(args.log_dir, 'best_model.pkl')\n",
    "    torch_save_model(model, checkpoint_pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running detailed inference\n",
      "Split: test\n",
      "accuracy 0.7142348287433681\n",
      "Accuracies per sentence saliency [-1 - 4]. Note \"-1\" designates ShapeGlot\n",
      "saliency\n",
      "0    0.757517\n",
      "1    0.721539\n",
      "2    0.694087\n",
      "3    0.686796\n",
      "4    0.687980\n",
      "Name: guessed_correct, dtype: float64\n",
      "\n",
      "\n",
      "Average Performance in hard pairs for/when using_all_data: 0.674614889671095\n",
      "Average Performance in easy pairs for/when using_all_data: 0.7531203566121842\n",
      "Average Performance in hard pairs for/when excluding_sg_examples: 0.674614889671095\n",
      "Average Performance in easy pairs for/when excluding_sg_examples: 0.7531203566121842\n",
      "Accuracy by grouping on: target_object_class\n",
      "target_object_class\n",
      "person        0.466667\n",
      "plant         0.566563\n",
      "scissors      0.597222\n",
      "skateboard    0.622642\n",
      "bag           0.630303\n",
      "knife         0.654709\n",
      "helmet        0.658683\n",
      "guitar        0.659829\n",
      "lamp          0.665602\n",
      "faucet        0.666006\n",
      "pistol        0.667387\n",
      "bookshelf     0.673292\n",
      "cabinet       0.683417\n",
      "display       0.688919\n",
      "bowl          0.697761\n",
      "bed           0.700603\n",
      "bathtub       0.702842\n",
      "mug           0.704000\n",
      "trashbin      0.707692\n",
      "flowerpot     0.710794\n",
      "dresser       0.711728\n",
      "vase          0.717890\n",
      "bottle        0.719449\n",
      "sofa          0.722233\n",
      "cap           0.722513\n",
      "clock         0.727273\n",
      "chair         0.733493\n",
      "table         0.749102\n",
      "airplane      0.753262\n",
      "bench         0.755452\n",
      "\n",
      "Accuracy by grouping on: source_dataset\n",
      "source_dataset\n",
      "PartNet     0.661642\n",
      "ModelNet    0.699784\n",
      "ShapeNet    0.716598\n",
      "\n",
      "Accuracy by grouping on: target_dataset\n",
      "target_dataset\n",
      "PartNet     0.667864\n",
      "ModelNet    0.674594\n",
      "ShapeNet    0.719201\n",
      "\n",
      "Examples containing distractors that where seen as targets or distractors during training 51831 / 53341\n",
      "Accuracy when the distractor was seen in training 0.714244371129247\n",
      "Accuracy when the distractor was *not* seen in training 0.713907284768212\n",
      "\n",
      "\n",
      "Split: val\n",
      "accuracy 0.7154861498419781\n",
      "Accuracies per sentence saliency [-1 - 4]. Note \"-1\" designates ShapeGlot\n",
      "saliency\n",
      "0    0.756098\n",
      "1    0.715709\n",
      "2    0.699815\n",
      "3    0.689444\n",
      "4    0.704715\n",
      "Name: guessed_correct, dtype: float64\n",
      "\n",
      "\n",
      "Average Performance in hard pairs for/when using_all_data: 0.6808240650891991\n",
      "Average Performance in easy pairs for/when using_all_data: 0.7498888724255445\n",
      "Average Performance in hard pairs for/when excluding_sg_examples: 0.6808240650891991\n",
      "Average Performance in easy pairs for/when excluding_sg_examples: 0.7498888724255445\n",
      "Accuracy by grouping on: target_object_class\n",
      "target_object_class\n",
      "helmet        0.531250\n",
      "person        0.533333\n",
      "plant         0.536313\n",
      "scissors      0.550562\n",
      "knife         0.601140\n",
      "bag           0.642424\n",
      "lamp          0.643364\n",
      "guitar        0.648054\n",
      "bed           0.686667\n",
      "bookshelf     0.686957\n",
      "pistol        0.688259\n",
      "faucet        0.688462\n",
      "bowl          0.695035\n",
      "cabinet       0.696809\n",
      "display       0.701493\n",
      "flowerpot     0.703557\n",
      "dresser       0.704209\n",
      "bottle        0.709459\n",
      "clock         0.713987\n",
      "sofa          0.722439\n",
      "table         0.729388\n",
      "skateboard    0.730496\n",
      "bathtub       0.733333\n",
      "mug           0.734848\n",
      "vase          0.742857\n",
      "trashbin      0.748148\n",
      "cap           0.753769\n",
      "bench         0.761942\n",
      "chair         0.764897\n",
      "airplane      0.769334\n",
      "\n",
      "Accuracy by grouping on: source_dataset\n",
      "source_dataset\n",
      "PartNet     0.670886\n",
      "ModelNet    0.690233\n",
      "ShapeNet    0.718985\n",
      "\n",
      "Accuracy by grouping on: target_dataset\n",
      "target_dataset\n",
      "PartNet     0.661333\n",
      "ModelNet    0.688643\n",
      "ShapeNet    0.719284\n",
      "\n",
      "Examples containing distractors that where seen as targets or distractors during training 26205 / 26895\n",
      "Accuracy when the distractor was seen in training 0.7165426445334859\n",
      "Accuracy when the distractor was *not* seen in training 0.6753623188405797\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "# Testing\n",
    "##\n",
    "\n",
    "logger.info('Running detailed inference')\n",
    "\n",
    "train_df = dataloaders['train'].dataset.df\n",
    "training_examples = set(train_df.target.unique())\n",
    "training_examples = training_examples.union(set(train_df.distractor_1.unique()))\n",
    "\n",
    "evaluation_results = dict()  # store those in the end.\n",
    "\n",
    "for split in ['test', 'val']:\n",
    "    evaluation_results[split] = dict()\n",
    "    logger.info(f'Split: {split}')\n",
    "\n",
    "    res = evaluate_listener(model, dataloaders[split], device=device, return_logits=True)\n",
    "    evaluation_results[split]['accuracy'] = res['accuracy']\n",
    "    logger.info(f\"accuracy {res['accuracy']}\")\n",
    "\n",
    "    probabilities = torch.softmax(torch.Tensor(res['logits']), dim=1)\n",
    "    guess_correct = torch.argmax(probabilities, 1) == 1\n",
    "    assert abs(guess_correct.double().mean() - res['accuracy']) < 10e-5\n",
    "\n",
    "    augmented_df = dataloaders[split].dataset.df.copy(deep=True)\n",
    "    augmented_df = augmented_df.assign(guessed_correct=guess_correct.tolist())\n",
    "    augmented_df = augmented_df.assign(guessed_probs=probabilities.tolist())\n",
    "    evaluation_results[split]['augmented_df_with_predictions'] = augmented_df.copy(deep=True)\n",
    "\n",
    "    # ShapeTalk vs. ShapeGlot analysis\n",
    "    sg_mask = augmented_df.assignmentid == 'shapeglot'\n",
    "    if sg_mask.sum() > 0:\n",
    "        acc_on_not_sg = augmented_df[~sg_mask]['guessed_correct'].mean()\n",
    "        evaluation_results[split]['accuracy_excluding_SG_examples'] = acc_on_not_sg\n",
    "        logger.info(f'Accuracy on examples not from ShapeGlot {acc_on_not_sg}\\n')\n",
    "\n",
    "    # Saliency analysis\n",
    "    logger.info('Accuracies per sentence saliency [-1 - 4]. Note \"-1\" designates ShapeGlot')\n",
    "    accuracy_per_saliency = augmented_df.groupby('saliency')['guessed_correct'].mean()\n",
    "    evaluation_results[split]['accuracy_per_saliency'] = accuracy_per_saliency\n",
    "    logger.info(accuracy_per_saliency)\n",
    "    logger.info('\\n')\n",
    "\n",
    "\n",
    "    # Hard vs. easy context analysis\n",
    "    missing_context_mask = (augmented_df['hard_context'].isna()) & ~(augmented_df.assignmentid == 'shapeglot')\n",
    "    n_missing = missing_context_mask.sum()\n",
    "    if n_missing > 0:\n",
    "        logger.info(f'Warning: {n_missing} non-shapeglot stimuli do not have context hardness information')\n",
    "\n",
    "    for tag in ['using_all_data', 'excluding_sg_examples']:\n",
    "        if tag == 'using_all_data':\n",
    "            temp = augmented_df[~augmented_df.hard_context.isna()]\n",
    "        elif tag == 'excluding_sg_examples':\n",
    "            temp = augmented_df[(~augmented_df.hard_context.isna()) & (augmented_df.assignmentid != 'shapeglot')]\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        accuracy_on_hard = temp[temp.hard_context]['guessed_correct'].mean()\n",
    "        evaluation_results[split][f'accuracy_on_hard_{tag}'] = accuracy_on_hard\n",
    "        logger.info(f\"Average Performance in hard pairs for/when {tag}: {accuracy_on_hard}\")\n",
    "\n",
    "        accuracy_on_easy = temp[~temp.hard_context]['guessed_correct'].mean()\n",
    "        evaluation_results[split][f'accuracy_on_easy_{tag}'] = accuracy_on_easy\n",
    "        logger.info(f\"Average Performance in easy pairs for/when {tag}: {accuracy_on_easy}\")\n",
    "\n",
    "\n",
    "    ## per shape-class, per source, or target dataset (ShapeNet, vs. ModelNet vs. PartNet) analysis\n",
    "    for key in ['target_object_class', 'source_dataset', 'target_dataset']:\n",
    "        acc_per_key = augmented_df.groupby(key)['guessed_correct'].mean()\n",
    "        evaluation_results[split][f'accuracy_analyzed_per_{key}'] = acc_per_key\n",
    "        logger.info(f'Accuracy by grouping on: {key}')\n",
    "        logger.info(acc_per_key.sort_values().to_string() + '\\n')\n",
    "\n",
    "\n",
    "    ## Final and more \"Esoteric\" analysis regarding the effect of seeing the distractor during the listening training.\n",
    "    if split != 'train':\n",
    "        targets = set(augmented_df.target.unique())\n",
    "        distractor_in_training = augmented_df.distractor_1.isin(training_examples)\n",
    "        distractor_fraction_in_train = f\"{distractor_in_training.sum()} / {len(distractor_in_training)}\"\n",
    "        evaluation_results[split]['distractor_fraction_in_train'] = distractor_fraction_in_train\n",
    "        logger.info(\n",
    "            f'Examples containing distractors that where seen as targets or '\n",
    "            f'distractors during training {distractor_fraction_in_train}')\n",
    "\n",
    "        ac1 = augmented_df[distractor_in_training].guessed_correct.mean()\n",
    "        evaluation_results[split]['accuracy_when_distractor_in_train'] = ac1\n",
    "        logger.info(f'Accuracy when the distractor was seen in training {ac1}')\n",
    "        ac2 = augmented_df[~distractor_in_training].guessed_correct.mean()\n",
    "        evaluation_results[split]['accuracy_when_distractor_not_in_train'] = ac2\n",
    "        logger.info(f'Accuracy when the distractor was *not* seen in training {ac2}')\n",
    "    logger.info('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(args, 'save_analysis_results') and args.save_analysis_results:\n",
    "    pickle_data(osp.join(args.log_dir, 'analysis_of_trained_listener.pkl'), evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "changeit3d",
   "language": "python",
   "name": "changeit3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "6998593bef615868a01884a31ab15a79588720b64ac6baa396e0d2c68b9e119c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
