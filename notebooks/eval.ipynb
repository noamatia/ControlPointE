{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noamatia/miniconda3/envs/point-e/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jitting Chamfer 3D\n",
      "Loaded JIT 3D CUDA chamfer distance\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/noamatia/repos/control_point_e\")\n",
    "sys.path.insert(0, \"/home/noamatia/repos/control_point_e/changeit3d\")\n",
    "import tqdm\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "from functools import partial\n",
    "from shapetalk import ShapeTalk\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from control_point_e import ControlPointE\n",
    "from point_e.util.point_cloud import PointCloud\n",
    "from changeit3d.utils.basics import parallel_apply\n",
    "from point_e.util.plotting import render_point_cloud\n",
    "from changeit3d.language.vocabulary import Vocabulary\n",
    "from point_e.diffusion.sampler import PointCloudSampler\n",
    "from changeit3d.in_out.pointcloud import pc_loader_from_npz\n",
    "from changeit3d.evaluation.all_metrics import run_all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"chair\"\n",
    "num_samples = 100\n",
    "n_sample_points = 2048\n",
    "ckpt = \"epoch=99-step=52000.ckpt\"\n",
    "base_dir = \"/scratch/noam/control_point_e\"\n",
    "top_pc_dir = \"/scratch/noam/shapetalk/point_clouds/scaled_to_align_rendering\"\n",
    "run_name = \"08_06_2024_16_10_17_train_chair_chamfer_0_5_val_chair_prompt_key_utterance_cond_drop_0_5_copy_0_1_copy_prompt_COPY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(base_dir, \"eval\", obj, f\"{num_samples}_random_samples\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "dataset_dir = os.path.join(base_dir, \"datasets\", obj, \"val.csv\")\n",
    "samples_path = os.path.join(output_dir, \"samples.csv\")\n",
    "if not os.path.exists(samples_path):\n",
    "    df = pd.read_csv(dataset_dir)\n",
    "    df = df.sample(num_samples)\n",
    "    df.to_csv(samples_path, index=False)\n",
    "else:\n",
    "    df = pd.read_csv(samples_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating ShapeTalk dataset:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating ShapeTalk dataset: 100%|██████████| 100/100 [00:00<00:00, 518.78it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = ShapeTalk(\n",
    "    df=df,\n",
    "    batch_size=6,\n",
    "    device=device,\n",
    "    num_points=1024,\n",
    "    prompt_key=\"utterance\",\n",
    ")\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=6, shuffle=False)\n",
    "model = ControlPointE.load_from_checkpoint(\n",
    "    os.path.join(f\"/scratch/noam/control_point_e/executions\", run_name, \"checkpoints\", ckpt),\n",
    "    lr=7e-5 * 0.4,\n",
    "    dev=device,\n",
    "    batch_size=6,\n",
    "    timesteps=1024,\n",
    "    num_points=1024,\n",
    "    copy_prob=0.1,\n",
    "    copy_prompt=\"COPY\",\n",
    "    cond_drop_prob=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sampler = PointCloudSampler(\n",
    "            s_churn=[3],\n",
    "            sigma_max=[120],\n",
    "            device=model.dev,\n",
    "            sigma_min=[1e-3],\n",
    "            num_points=[1024],\n",
    "            use_karras=[True],\n",
    "            karras_steps=[64],\n",
    "            models=[model.model],\n",
    "            guidance_scale=[3.0],\n",
    "            aux_channels=[\"R\", \"G\", \"B\"],\n",
    "            diffusions=[model.diffusion],\n",
    "            model_kwargs_key_filter=[\"texts\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "i, j = 0, 0\n",
    "output = None\n",
    "output_path = os.path.join(output_dir, f\"{run_name}.pt\")\n",
    "results_source_dir = os.path.join(output_dir, \"results\", \"source\")\n",
    "os.makedirs(results_source_dir, exist_ok=True)\n",
    "results_target_dir = os.path.join(output_dir, \"results\", \"target\")\n",
    "os.makedirs(results_target_dir, exist_ok=True)\n",
    "if not os.path.exists(output_path):\n",
    "    for batch in tqdm.tqdm(data_loader):\n",
    "        source_pcs = model.sampler.output_to_point_clouds(batch[\"source_latents\"])\n",
    "        target_pcs = model.sampler.output_to_point_clouds(batch[\"target_latents\"])\n",
    "        for pc in source_pcs:\n",
    "            render_point_cloud(\n",
    "                pc,\n",
    "                theta=np.pi,\n",
    "                output_path=os.path.join(results_source_dir, f\"{i}.png\"),\n",
    "            )\n",
    "            i += 1\n",
    "        for pc in target_pcs:\n",
    "            render_point_cloud(\n",
    "                pc,\n",
    "                theta=np.pi,\n",
    "                output_path=os.path.join(results_target_dir, f\"{j}.png\"),\n",
    "            )\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [40:44<00:00, 143.81s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "output = None\n",
    "output_path = os.path.join(output_dir, f\"{run_name}.pt\")\n",
    "results_dir = os.path.join(output_dir, \"results\", run_name, \"outputs\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "if not os.path.exists(output_path):\n",
    "    for batch in tqdm.tqdm(data_loader):\n",
    "        prompts, source_latents = (batch[\"prompts\"], batch[\"source_latents\"].to(device))\n",
    "        curr_output = model.sampler.sample_batch(\n",
    "            guidances=[source_latents, None],\n",
    "            model_kwargs={\"texts\": prompts},\n",
    "            batch_size=6,\n",
    "        )\n",
    "        pcs = model.sampler.output_to_point_clouds(curr_output)\n",
    "        for pc in pcs:\n",
    "            render_point_cloud(\n",
    "                pc,\n",
    "                theta=np.pi,\n",
    "                output_path=os.path.join(results_dir, f\"{i}.png\"),\n",
    "            )\n",
    "            i += 1\n",
    "        if output is None:\n",
    "            output = curr_output.detach().cpu()\n",
    "        else:\n",
    "            output = torch.cat((output, curr_output.detach().cpu()), dim=0)\n",
    "    torch.save(output, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [34:50<00:00, 122.99s/it]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "model.sampler.injection_percentile = 0.5\n",
    "model.sampler.injection_t = 30\n",
    "output = None\n",
    "suffix_str = f\"injection_t_{model.sampler.injection_t}_p_{str(model.sampler.injection_percentile).replace('.', '_')}\"\n",
    "output_path = os.path.join(output_dir, f\"{run_name}_{suffix_str}.pt\")\n",
    "results_dir = os.path.join(output_dir, \"results\", run_name, f\"outputs_{suffix_str}\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "copy_dir = os.path.join(output_dir, \"results\", run_name, f\"copy_{suffix_str}\")\n",
    "os.makedirs(copy_dir, exist_ok=True)\n",
    "if not os.path.exists(output_path):\n",
    "    for batch in tqdm.tqdm(data_loader):\n",
    "        prompts, source_latents = batch[\"prompts\"], batch[\"source_latents\"]\n",
    "        for prompt, source_latent in zip(prompts, source_latents):\n",
    "            injection_seed_dir = os.path.join(output_dir, \"seeds\", f\"{i}\")\n",
    "            os.makedirs(injection_seed_dir, exist_ok=True)\n",
    "            model.sampler.injection_seed_dir = injection_seed_dir\n",
    "            curr_output = model.sampler.sample_batch(\n",
    "                guidances=[torch.stack([source_latent, source_latent]).to(device)],\n",
    "                model_kwargs={\"texts\": [\"COPY\", prompt]},\n",
    "                batch_size=2,\n",
    "            )\n",
    "            pcs = model.sampler.output_to_point_clouds(curr_output)\n",
    "            render_point_cloud(\n",
    "                pcs[0],\n",
    "                theta=np.pi,\n",
    "                output_path=os.path.join(copy_dir, f\"{i}.png\"),\n",
    "            )\n",
    "            render_point_cloud(\n",
    "                pcs[1],\n",
    "                theta=np.pi,\n",
    "                output_path=os.path.join(results_dir, f\"{i}.png\"),\n",
    "            )\n",
    "            i += 1\n",
    "            if output is None:\n",
    "                output = curr_output.detach().cpu()[1:]\n",
    "            else:\n",
    "                output = torch.cat((output, curr_output.detach().cpu()[1:]), dim=0)\n",
    "    torch.save(output, output_path)\n",
    "model.sampler.precentile = None\n",
    "model.sampler.injection_t = None\n",
    "model.sampler.injection_seed_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"<style>\\n\"\n",
    "html += \"td { font-size: 64px; } /* Increase the font size */\\n\"\n",
    "html += \"img { width: 1000px; height: 1000px; object-fit: cover; } /* Set square dimensions */\\n\"\n",
    "html += \"</style>\\n\"\n",
    "html += \"<table>\\n\"\n",
    "for i, row in df.iterrows():\n",
    "    html += \"<tr><td><b>prompt</b></td><td><b>shapetalk</b></td><td><b>spice_p_1_0</b></td><td><b>spice_p_0_9</b></td><td><b>spice_p_0_75</b></td><td><b>spice_p_0_5</b></td></tr>\\n\"\n",
    "    html += f\"<tr><td>{row.utterance}</td><td><img src='source/{i}.png'></td><td><img src='{run_name}/copy_injection_t_30_p_1_0/{i}.png'></td><td><img src='{run_name}/copy_injection_t_30_p_0_9/{i}.png'></td><td><img src='{run_name}/copy_injection_t_30_p_0_75/{i}.png'></td><td><img src='{run_name}/copy_injection_t_30_p_0_5/{i}.png'></td></tr>\\n\"\n",
    "    html += f\"<tr><td></td><td><img src='target/{i}.png'></td><td><img src='{run_name}/outputs_injection_t_30_p_1_0/{i}.png'></td><td><img src='{run_name}/outputs_injection_t_30_p_0_9/{i}.png'></td><td><img src='{run_name}/outputs_injection_t_30_p_0_75/{i}.png'></td><td><img src='{run_name}/outputs_injection_t_30_p_0_5/{i}.png'></td></tr>\\n\"\n",
    "html += \"</table>\"\n",
    "with open(os.path.join(output_dir, \"results\", \"index.html\"), \"w\") as f:\n",
    "    f.write(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-shape_talk_file', type=str, default=\"/scratch/noam/shapetalk/language/shapetalk_preprocessed_public_version_0.csv\")\n",
    "parser.add_argument('-vocab_file', type=str, default=\"/scratch/noam/shapetalk/language/vocabulary.pkl\")\n",
    "parser.add_argument('-latent_codes_file', type=str, default=\"/scratch/noam/changeit3d/pretrained/shape_latents/pcae_latent_codes.pkl\")    \n",
    "parser.add_argument('-pretrained_changeit3d', type=str, default=\"/scratch/noam/changeit3d/pretrained/changers/pcae_based/all_shapetalk_classes/decoupling_mag_direction/idpen_0.01_sc_False/best_model.pt\")    \n",
    "parser.add_argument('-top_pc_dir', type=str, default=\"/scratch/noam/shapetalk/point_clouds/scaled_to_align_rendering\")\n",
    "parser.add_argument('--restrict_shape_class', type=str, nargs='*', default=['chair'])        \n",
    "parser.add_argument('--pretrained_shape_classifier', type=str,default=\"/scratch/noam/changeit3d/pretrained/pc_classifiers/rs_2022/all_shapetalk_classes/best_model.pkl\")    \n",
    "parser.add_argument('--compute_fpd', type=bool, default=True)\n",
    "parser.add_argument('--shape_part_classifiers_top_dir', type=str, default=\"/scratch/noam/changeit3d/pretrained/part_predictors/shapenet_core_based\")\n",
    "parser.add_argument('--pretrained_oracle_listener', type=str, default=\"/scratch/noam/changeit3d/pretrained/listeners/oracle_listener/all_shapetalk_classes/rs_2023/listener_dgcnn_based/ablation1/best_model.pkl\")\n",
    "parser.add_argument('--shape_generator_type', type=str, default=\"pcae\", choices=[\"pcae\", \"sgf\", \"imnet\"])\n",
    "parser.add_argument('--pretrained_shape_generator', type=str, required=False, default=\"/scratch/noam/changeit3d/pretrained/pc_autoencoders/pointnet/rs_2022/points_4096/all_classes/scaled_to_align_rendering/08-07-2022-22-23-42/best_model.pt\")\n",
    "parser.add_argument('--n_sample_points', type=int, default=2048)\n",
    "parser.add_argument('--sub_sample_dataset', type=int)\n",
    "parser.add_argument('--gpu_id', type=int, default=0)\n",
    "parser.add_argument('--save_reconstructions', default=False, type=bool)\n",
    "parser.add_argument('--use_timestamp', default=False, type=bool)\n",
    "parser.add_argument('--experiment_tag', type=str)\n",
    "parser.add_argument('--random_seed', type=int, default=2022)\n",
    "parser.add_argument('--log_dir', type=str, default='./logs')\n",
    "parser.add_argument('--clean_train_val_data', type=bool, default=False)\n",
    "parser.add_argument('-pretrained_listener_file', type=str, default=\"/scratch/noam/changeit3d/pretrained/listeners/oracle_listener/all_shapetalk_classes/rs_2023/listener_dgcnn_based/ablation1/best_model.pkl\")\n",
    "parser.add_argument('--batch_size', type=int, default=1024)\n",
    "parser.add_argument('--num_workers', type=int, default=10)\n",
    "parser.add_argument('--evaluate_retrieval_version', type=bool, default=False)\n",
    "parser.add_argument('--f', type=str)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('stdout_logger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_shapes = torch.load(output_path).transpose(1, 2).cpu().numpy()\n",
    "theta = np.pi * 1 / 2   \n",
    "rotation = np.array(\n",
    "    [\n",
    "        [np.cos(theta), -np.sin(theta), 0.0],\n",
    "        [np.sin(theta), np.cos(theta), 0.0],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "transformed_shapes = transformed_shapes @ rotation\n",
    "theta = np.pi / 2\n",
    "rotation = np.array(\n",
    "    [\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, np.cos(theta), -np.sin(theta)],\n",
    "        [0.0, np.sin(theta), np.cos(theta)],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "transformed_shapes = transformed_shapes @ rotation\n",
    "gt_pc_files = df.source_uid.apply(lambda x: osp.join(top_pc_dir, x + \".npz\")).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_loader =  partial(pc_loader_from_npz, n_samples=n_sample_points, random_seed=2022)\n",
    "gt_pcs = parallel_apply(gt_pc_files, pc_loader, n_processes=1)\n",
    "gt_pcs = np.array(gt_pcs)\n",
    "vocab = Vocabulary.load(args.vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pcs_decoded = None\n",
    "gt_path = os.path.join(output_dir, \"gt.pt\")\n",
    "if not os.path.exists(gt_path):\n",
    "    for batch in tqdm.tqdm(data_loader):\n",
    "        source_latents = batch[\"source_latents\"]\n",
    "        samples = model.sampler.sample_batch(\n",
    "                                batch_size=6,\n",
    "                                model_kwargs={},\n",
    "                                prev_samples=source_latents,\n",
    "                            )\n",
    "        pcs = model.sampler.output_to_point_clouds(samples)\n",
    "        for pc in pcs:\n",
    "            pc = pc.random_sample(2048)\n",
    "            if gt_pcs_decoded is None:\n",
    "                gt_pcs_decoded = pc.encode().unsqueeze(0)\n",
    "            else:\n",
    "                gt_pcs_decoded = torch.cat((gt_pcs_decoded, pc.encode().unsqueeze(0)), dim=0)\n",
    "    gt_pcs_decoded = gt_pcs[:, :3, :]\n",
    "    torch.save(gt_pcs_decoded, gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pcs_decoded = torch.load(gt_path)[:num_samples].transpose(1, 2).cpu().numpy()\n",
    "theta = np.pi * 1 / 2   \n",
    "rotation = np.array(\n",
    "    [\n",
    "        [np.cos(theta), -np.sin(theta), 0.0],\n",
    "        [np.sin(theta), np.cos(theta), 0.0],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "gt_pcs_decoded = gt_pcs_decoded @ rotation\n",
    "theta = np.pi / 2\n",
    "rotation = np.array(\n",
    "    [\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, np.cos(theta), -np.sin(theta)],\n",
    "        [0.0, np.sin(theta), np.cos(theta)],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "gt_pcs_decoded = gt_pcs_decoded @ rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.utterance_spelled.values\n",
    "gt_classes = df.source_object_class.values\n",
    "changeit3d_outputs = torch.load(os.path.join(output_dir, \"changeit3d.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chamfer Distance (all pairs), Average: 2.865\n",
      "Chamfer Distance (all pairs), Average: 2.865\n",
      "Chamfer Distance (all pairs), Average: 2.865\n",
      "Chamfer Distance (all pairs), Average: 2.865\n",
      "Chamfer Distance (all pairs), Average: 2.865\n",
      "Chamfer Distance (all pairs), Average: 2.865\n",
      "Chamfer Distance (all pairs), Average, per class:\n",
      "Chamfer Distance (all pairs), Average, per class:\n",
      "Chamfer Distance (all pairs), Average, per class:\n",
      "Chamfer Distance (all pairs), Average, per class:\n",
      "Chamfer Distance (all pairs), Average, per class:\n",
      "Chamfer Distance (all pairs), Average, per class:\n",
      "  shape_class  holistic-chamfer\n",
      "0       chair             2.865\n",
      "  shape_class  holistic-chamfer\n",
      "0       chair             2.865\n",
      "  shape_class  holistic-chamfer\n",
      "0       chair             2.865\n",
      "  shape_class  holistic-chamfer\n",
      "0       chair             2.865\n",
      "  shape_class  holistic-chamfer\n",
      "0       chair             2.865\n",
      "  shape_class  holistic-chamfer\n",
      "0       chair             2.865\n",
      "LAB Average:0.9895337224006653\n",
      "LAB Average:0.9895337224006653\n",
      "LAB Average:0.9895337224006653\n",
      "LAB Average:0.9895337224006653\n",
      "LAB Average:0.9895337224006653\n",
      "LAB Average:0.9895337224006653\n",
      "LAB-related-metric: Times edit is favored by listener against the original input, Average:1.0\n",
      "LAB-related-metric: Times edit is favored by listener against the original input, Average:1.0\n",
      "LAB-related-metric: Times edit is favored by listener against the original input, Average:1.0\n",
      "LAB-related-metric: Times edit is favored by listener against the original input, Average:1.0\n",
      "LAB-related-metric: Times edit is favored by listener against the original input, Average:1.0\n",
      "LAB-related-metric: Times edit is favored by listener against the original input, Average:1.0\n",
      "LAB (all pairs), Average, per class:\n",
      "LAB (all pairs), Average, per class:\n",
      "LAB (all pairs), Average, per class:\n",
      "LAB (all pairs), Average, per class:\n",
      "LAB (all pairs), Average, per class:\n",
      "LAB (all pairs), Average, per class:\n",
      "  shape_class       LAB\n",
      "0       chair  0.989534\n",
      "  shape_class       LAB\n",
      "0       chair  0.989534\n",
      "  shape_class       LAB\n",
      "0       chair  0.989534\n",
      "  shape_class       LAB\n",
      "0       chair  0.989534\n",
      "  shape_class       LAB\n",
      "0       chair  0.989534\n",
      "  shape_class       LAB\n",
      "0       chair  0.989534\n",
      "A classifier trained to recognize 30 shape classes was loaded.\n",
      "A classifier trained to recognize 30 shape classes was loaded.\n",
      "A classifier trained to recognize 30 shape classes was loaded.\n",
      "A classifier trained to recognize 30 shape classes was loaded.\n",
      "A classifier trained to recognize 30 shape classes was loaded.\n",
      "A classifier trained to recognize 30 shape classes was loaded.\n",
      "\n",
      " (Average) Class Distortion for chair: 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion for chair: 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion for chair: 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion for chair: 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion for chair: 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion for chair: 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion (all classes): 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion (all classes): 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion (all classes): 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion (all classes): 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion (all classes): 0.011931896209716797\n",
      "\n",
      " (Average) Class Distortion (all classes): 0.011931896209716797\n",
      "\n",
      "The classifier guesses the classes of the ** gt pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** gt pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** gt pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** gt pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** gt pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** gt pointclouds ** with accuracy 1.0\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The classifier guesses the classes of the ** transformed pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** transformed pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** transformed pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** transformed pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** transformed pointclouds ** with accuracy 1.0\n",
      "\n",
      "The classifier guesses the classes of the ** transformed pointclouds ** with accuracy 1.0\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "| shape_class   |   guessed_correct |\n",
      "|:--------------|------------------:|\n",
      "| chair         |                 1 |\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Class = chair, FPD-score = 675.487\n",
      "Class = chair, FPD-score = 675.487\n",
      "Class = chair, FPD-score = 675.487\n",
      "Class = chair, FPD-score = 675.487\n",
      "Class = chair, FPD-score = 675.487\n",
      "Class = chair, FPD-score = 675.487\n",
      "Average across all classes=675.487\n",
      "\n",
      "Average across all classes=675.487\n",
      "\n",
      "Average across all classes=675.487\n",
      "\n",
      "Average across all classes=675.487\n",
      "\n",
      "Average across all classes=675.487\n",
      "\n",
      "Average across all classes=675.487\n",
      "\n",
      "(l)-GD excluding part(s) (chair): 2.985\n",
      "(l)-GD excluding part(s) (chair): 2.985\n",
      "(l)-GD excluding part(s) (chair): 2.985\n",
      "(l)-GD excluding part(s) (chair): 2.985\n",
      "(l)-GD excluding part(s) (chair): 2.985\n",
      "(l)-GD excluding part(s) (chair): 2.985\n",
      "(l)-GD on the part(s) (chair): 4.483\n",
      "(l)-GD on the part(s) (chair): 4.483\n",
      "(l)-GD on the part(s) (chair): 4.483\n",
      "(l)-GD on the part(s) (chair): 4.483\n",
      "(l)-GD on the part(s) (chair): 4.483\n",
      "(l)-GD on the part(s) (chair): 4.483\n",
      "GD on entire shapes when both have predicted referred parts  (chair): 2.865\n",
      "GD on entire shapes when both have predicted referred parts  (chair): 2.865\n",
      "GD on entire shapes when both have predicted referred parts  (chair): 2.865\n",
      "GD on entire shapes when both have predicted referred parts  (chair): 2.865\n",
      "GD on entire shapes when both have predicted referred parts  (chair): 2.865\n",
      "GD on entire shapes when both have predicted referred parts  (chair): 2.865\n",
      "(l)-GD on the part(s) normalized (chair): 0.639\n",
      "(l)-GD on the part(s) normalized (chair): 0.639\n",
      "(l)-GD on the part(s) normalized (chair): 0.639\n",
      "(l)-GD on the part(s) normalized (chair): 0.639\n",
      "(l)-GD on the part(s) normalized (chair): 0.639\n",
      "(l)-GD on the part(s) normalized (chair): 0.639\n",
      "\n",
      "---------\n",
      "\n",
      "---------\n",
      "\n",
      "---------\n",
      "\n",
      "---------\n",
      "\n",
      "---------\n",
      "\n",
      "---------\n",
      "without_parts_average: 2.985\n",
      "without_parts_average: 2.985\n",
      "without_parts_average: 2.985\n",
      "without_parts_average: 2.985\n",
      "without_parts_average: 2.985\n",
      "without_parts_average: 2.985\n",
      "GD_on_pairs_with_parts_average: 2.865\n",
      "GD_on_pairs_with_parts_average: 2.865\n",
      "GD_on_pairs_with_parts_average: 2.865\n",
      "GD_on_pairs_with_parts_average: 2.865\n",
      "GD_on_pairs_with_parts_average: 2.865\n",
      "GD_on_pairs_with_parts_average: 2.865\n",
      "with_parts_average: 4.483\n",
      "with_parts_average: 4.483\n",
      "with_parts_average: 4.483\n",
      "with_parts_average: 4.483\n",
      "with_parts_average: 4.483\n",
      "with_parts_average: 4.483\n",
      "with_parts_normalized_average: 0.639\n",
      "with_parts_normalized_average: 0.639\n",
      "with_parts_normalized_average: 0.639\n",
      "with_parts_normalized_average: 0.639\n",
      "with_parts_normalized_average: 0.639\n",
      "with_parts_normalized_average: 0.639\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "results_on_metrics = run_all_metrics(changeit3d_outputs[i:i+1], gt_pcs[i:i+1], gt_classes[i:i+1], sentences[i:i+1], vocab, args, logger)\n",
    "# results_on_metrics = run_all_metrics(transformed_shapes[i:i+1], gt_pcs[i:i+1], gt_classes[i:i+1], sentences[i:i+1], vocab, args, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = 0\n",
    "n_examples = 100\n",
    "results_dir = os.path.join(output_dir, \"results\", run_name)\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "for batch in tqdm.tqdm(data_loader):\n",
    "    if curr >= n_examples:\n",
    "        break\n",
    "    prompts, source_latents, target_latents = (\n",
    "        batch[\"prompts\"],\n",
    "        batch[\"source_latents\"].to(device),\n",
    "        batch[\"target_latents\"].to(device),\n",
    "    )\n",
    "    samples = model.sampler.sample_batch(\n",
    "        batch_size=6,\n",
    "        model_kwargs={\"texts\": prompts},\n",
    "        guidances=[source_latents, None],\n",
    "    )\n",
    "    pcs = model.sampler.output_to_point_clouds(samples)\n",
    "    for i, (prompt, source_latent, target_latent) in enumerate(zip(prompts, source_latents, target_latents)):\n",
    "        if curr >= n_examples:\n",
    "            break\n",
    "        output_path = os.path.join(results_dir, f\"output_{curr}.png\")\n",
    "        fig = plot_point_cloud(pcs[i], theta=model.theta)\n",
    "        fig.savefig(output_path)\n",
    "        plt.close()\n",
    "        source_path = os.path.join(output_dir, \"results\", \"source\", f\"source_{curr}.png\")\n",
    "        if not os.path.exists(target_path):\n",
    "            samples = model.sampler.sample_batch(\n",
    "                            batch_size=1,\n",
    "                            model_kwargs={},\n",
    "                            prev_samples=source_latent.unsqueeze(0),\n",
    "                        )\n",
    "            pc = model.sampler.output_to_point_clouds(samples)[0]\n",
    "            fig = plot_point_cloud(pc, theta=model.theta)\n",
    "            fig.savefig(source_path)\n",
    "            plt.close()\n",
    "        target_path = os.path.join(output_dir, \"results\", \"target\", f\"target_{curr}.png\")\n",
    "        if not os.path.exists(target_path):\n",
    "            samples = model.sampler.sample_batch(\n",
    "                            batch_size=1,\n",
    "                            model_kwargs={},\n",
    "                            prev_samples=target_latent.unsqueeze(0),\n",
    "                        )       \n",
    "            pc = model.sampler.output_to_point_clouds(samples)[0]\n",
    "            fig = plot_point_cloud(pc, theta=model.theta)\n",
    "            fig.savefig(target_path)\n",
    "            plt.close()\n",
    "        curr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:39<00:00,  5.19s/it]\n"
     ]
    }
   ],
   "source": [
    "changeit3d_outputs = torch.load(os.path.join(output_dir, \"changeit3d.pt\"))\n",
    "theta = np.pi * 2 / 2   \n",
    "rotation = np.array(\n",
    "    [\n",
    "        [np.cos(theta), -np.sin(theta), 0.0],\n",
    "        [np.sin(theta), np.cos(theta), 0.0],\n",
    "        [0.0, 0.0, 1.0],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "changeit3d_outputs = changeit3d_outputs @ rotation\n",
    "theta = np.pi / 2\n",
    "rotation = np.array(\n",
    "    [\n",
    "        [1.0, 0.0, 0.0],\n",
    "        [0.0, np.cos(theta), -np.sin(theta)],\n",
    "        [0.0, np.sin(theta), np.cos(theta)],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "changeit3d_outputs = changeit3d_outputs @ rotation\n",
    "\n",
    "n_examples = 100\n",
    "results_dir = os.path.join(output_dir, \"results\", \"changeit3d\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "for curr in tqdm.tqdm(range(n_examples)):\n",
    "    changeit_path = os.path.join(output_dir, \"results\", \"changeit3d\", f\"changeit3d_{curr}.png\")\n",
    "    if not os.path.exists(changeit_path):\n",
    "        coords = changeit3d_outputs[curr]\n",
    "        channels = {k: np.zeros_like(coords[:, 0], dtype=np.float32) for k in [\"R\", \"G\", \"B\"]}\n",
    "        pc = PointCloud(coords, channels)\n",
    "        pc = pc.random_sample(1024)\n",
    "        samples = model.sampler.sample_batch(\n",
    "                        batch_size=1,\n",
    "                        model_kwargs={},\n",
    "                        prev_samples=pc.encode().unsqueeze(0).to(device),\n",
    "                    )\n",
    "        pc = model.sampler.output_to_point_clouds(samples)[0]\n",
    "        fig = plot_point_cloud(pc)\n",
    "        fig.savefig(changeit_path)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 17/84 [00:00<00:00, 981.58it/s]\n"
     ]
    }
   ],
   "source": [
    "run_names = [\n",
    "    \"07_31_2024_17_20_58_utterance_train_chair_val_chair_switch_0_chamfer_0_5\",\n",
    "    \"07_31_2024_20_53_33_utterance_train_chair_val_chair_switch_0_25_chamfer_0_5\",\n",
    "    \"07_31_2024_20_53_04_utterance_train_chair_val_chair_switch_0_5_chamfer_0_5\",\n",
    "]\n",
    "html = \"\"\"\n",
    "<style>\n",
    "    table {\n",
    "        font-size: 60px;\n",
    "    }\n",
    "</style>\n",
    "<table>\n",
    "\"\"\"\n",
    "html += \"<tr><td>prompt</td><td>source</td><td>target</td><td>changeit3d</td>\"\n",
    "for p in [\"0\", \"0_25\", \"0_5\"]:\n",
    "    html += f\"<td>{p}</td>\"\n",
    "html += \"</tr>\\n\"\n",
    "\n",
    "curr = 0\n",
    "n_examples = 100\n",
    "for batch in tqdm.tqdm(data_loader):\n",
    "    if curr >= n_examples:\n",
    "        break\n",
    "    prompts = batch[\"prompts\"]\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        if curr >= n_examples:\n",
    "            break\n",
    "        source_path = os.path.join(\"source\", f\"source_{curr}.png\")\n",
    "        target_path = os.path.join(\"target\", f\"target_{curr}.png\")\n",
    "        changeit_path = os.path.join(\"changeit3d\", f\"changeit3d_{curr}.png\")\n",
    "        html += f\"<tr><td>{prompt}</td><td><img src='{source_path}'></td><td><img src='{target_path}'></td><td><img src='{changeit_path}'></td>\"\n",
    "        for run_name in run_names:\n",
    "            output_path = os.path.join(run_name, f\"output_{curr}.png\")\n",
    "            html += f\"<td><img src='{output_path}'></td>\"\n",
    "        html += \"</tr>\\n\"\n",
    "        curr += 1\n",
    "html += \"</table>\"\n",
    "with open(os.path.join(output_dir, \"results\", \"results.html\"), \"w\") as f:\n",
    "    f.write(html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "point-e",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
